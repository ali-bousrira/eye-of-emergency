{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e457f91f",
   "metadata": {},
   "source": [
    "# 📘 Exploration de Texte (Text Mining) vs Traitement du Langage Naturel (NLP)\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Définition du Text Mining (Exploration de texte)\n",
    "\n",
    "Le **Text Mining** désigne l'ensemble des techniques permettant d'extraire des informations utiles ou cachées à partir de grands volumes de **textes non structurés**. Il s'agit d'une forme spécifique de fouille de données (data mining) appliquée aux données textuelles.\n",
    "\n",
    "**Objectifs principaux :**\n",
    "- Identifier des tendances, thèmes ou opinions (ex. : analyse de sentiments).\n",
    "- Extraire des entités nommées (personnes, lieux, dates).\n",
    "- Résumer automatiquement des documents.\n",
    "- Classifier ou regrouper des textes.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Définition du Natural Language Processing (NLP)\n",
    "\n",
    "Le **Traitement Automatique du Langage Naturel (TAL ou NLP)** est une branche de l’intelligence artificielle visant à permettre aux machines de **comprendre, interpréter, manipuler et générer** du langage humain.\n",
    "\n",
    "**Applications typiques :**\n",
    "- Traduction automatique (ex. : Google Translate).\n",
    "- Génération de texte (ex. : chatbots).\n",
    "- Analyse syntaxique et grammaticale.\n",
    "- Reconnaissance d'entités nommées.\n",
    "- Synthèse et reconnaissance vocale.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔸 Points communs entre Text Mining et NLP\n",
    "\n",
    "- 🌐 **Travail sur le langage naturel** (texte non structuré).\n",
    "- 🧠 **Utilisation de techniques similaires** : tokenisation, lemmatisation, analyse syntaxique, etc.\n",
    "- 🤖 **Domaines de l’intelligence artificielle**, souvent appuyés par le Machine Learning.\n",
    "- 📦 **But commun d’extraction d’information** et d’analyse de texte.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔸 Différences entre Text Mining et NLP\n",
    "\n",
    "| Critère                        | Text Mining                                     | Natural Language Processing (NLP)               |\n",
    "|-------------------------------|--------------------------------------------------|-------------------------------------------------|\n",
    "| 🎯 Objectif principal         | Extraire de l'information à partir de textes     | Comprendre et manipuler le langage naturel      |\n",
    "| 🧰 Outils utilisés             | Statistiques, classification, clustering         | Grammaires, modèles linguistiques, IA           |\n",
    "| 🧩 Approche                   | Analyse orientée données                         | Analyse orientée langage                        |\n",
    "| 📝 Type de sortie             | Résumés, clusters, visualisations                | Traductions, textes générés, réponses automatiques |\n",
    "| 🔄 Relation                   | Utilise des techniques NLP                      | Domaine plus large incluant le Text Mining      |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Résumé\n",
    "\n",
    "- Le **Text Mining** est une **application spécifique** utilisant des techniques de **NLP** pour extraire de l'information utile de textes.\n",
    "- Le **NLP** est un **domaine plus général** dédié à la compréhension et au traitement du langage humain.\n",
    "- Les deux sont **complémentaires** et souvent utilisés ensemble dans les systèmes d’analyse textuelle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679aaf1",
   "metadata": {},
   "source": [
    "# 🔍 Sous-domaines du NLP (Traitement du Langage Naturel)\n",
    "\n",
    "Le NLP regroupe plusieurs techniques et sous-domaines permettant aux machines de comprendre et manipuler le langage humain. Voici trois sous-domaines essentiels :\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ Analyse de sentiments (Sentiment Analysis)\n",
    "\n",
    "### 🧠 Définition\n",
    "L’analyse de sentiments vise à **déterminer l’émotion ou l’opinion** exprimée dans un texte. Elle est souvent utilisée pour analyser les avis clients, les tweets, ou les commentaires.\n",
    "\n",
    "### 📌 Exemples :\n",
    "- Texte : *\"J'adore ce produit, il est vraiment efficace !\"*  \n",
    "  → Sentiment : **positif**\n",
    "\n",
    "- Texte : *\"Ce service est horrible, je ne le recommande à personne.\"*  \n",
    "  → Sentiment : **négatif**\n",
    "\n",
    "### 📦 Applications :\n",
    "- E-réputation\n",
    "- Marketing digital\n",
    "- Veille concurrentielle\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ Reconnaissance d'entités nommées (Named Entity Recognition - NER)\n",
    "\n",
    "### 🧠 Définition\n",
    "La **NER** permet d’identifier et de classer automatiquement des **entités** dans un texte (comme les **noms de personnes**, **lieux**, **dates**, **organisations**, etc.).\n",
    "\n",
    "### 📌 Exemples :\n",
    "- Texte : *\"Emmanuel Macron a visité Berlin le 12 mars 2023.\"*  \n",
    "  → Entités extraites :\n",
    "  - **Personne** : Emmanuel Macron  \n",
    "  - **Lieu** : Berlin  \n",
    "  - **Date** : 12 mars 2023\n",
    "\n",
    "### 📦 Applications :\n",
    "- Extraction d’information\n",
    "- Moteurs de recherche intelligents\n",
    "- Systèmes de question-réponse\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Étiquetage morpho-syntaxique (Part-of-Speech Tagging - POS Tagging)\n",
    "\n",
    "### 🧠 Définition\n",
    "Le POS tagging consiste à attribuer à chaque mot d'une phrase sa **catégorie grammaticale** (nom, verbe, adjectif, etc.).\n",
    "\n",
    "### 📌 Exemple :\n",
    "- Phrase : *\"Le chat dort sur le canapé.\"*  \n",
    "  → Résultat :\n",
    "  - Le → Déterminant (DET)\n",
    "  - chat → Nom (NOUN)\n",
    "  - dort → Verbe (VERB)\n",
    "  - sur → Préposition (PREP)\n",
    "  - le → Déterminant (DET)\n",
    "  - canapé → Nom (NOUN)\n",
    "\n",
    "### 📦 Applications :\n",
    "- Analyse grammaticale\n",
    "- Traduction automatique\n",
    "- Résolution d’ambiguïtés linguistiques\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ En résumé\n",
    "\n",
    "| Sous-domaine        | Objectif principal                                 | Exemple d’application                  |\n",
    "|---------------------|----------------------------------------------------|----------------------------------------|\n",
    "| Analyse de sentiments | Déterminer l’émotion dans un texte                | Étude d’avis clients                   |\n",
    "| NER                  | Identifier des entités nommées                     | Extraction d’informations biographiques |\n",
    "| POS Tagging          | Identifier les catégories grammaticales des mots  | Analyse syntaxique                     |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec0779",
   "metadata": {},
   "source": [
    "# 💡 Applications concrètes du NLP\n",
    "\n",
    "Le NLP est largement utilisé dans de nombreux domaines du quotidien et de l'industrie. Voici quelques exemples d'applications concrètes :\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ Assistants vocaux et chatbots\n",
    "Les assistants comme **Siri, Alexa, Google Assistant** ou les **chatbots** utilisent le NLP pour comprendre les commandes vocales ou écrites, et y répondre de manière naturelle.\n",
    "\n",
    "🔸 Exemple :  \n",
    "- *\"Quel temps fait-il aujourd’hui ?\"* → réponse vocale ou textuelle fournie par l’assistant.\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ Analyse d’avis clients (Sentiment Analysis)\n",
    "Les entreprises utilisent le NLP pour analyser automatiquement les **avis en ligne** afin de comprendre l’opinion des clients sur leurs produits ou services.\n",
    "\n",
    "🔸 Exemple :  \n",
    "- *\"Le service est trop lent et le personnel désagréable.\"* → sentiment négatif.\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Traduction automatique\n",
    "Les outils comme **Google Translate** utilisent le NLP pour traduire un texte d’une langue à une autre en conservant le sens.\n",
    "\n",
    "🔸 Exemple :  \n",
    "- Traduction de *\"Bonjour, comment allez-vous ?\"* en *\"Hello, how are you?\"*\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ Systèmes de recommandation\n",
    "Le NLP peut analyser les contenus consultés (articles, livres, vidéos) pour proposer des **recommandations personnalisées** basées sur les préférences linguistiques de l’utilisateur.\n",
    "\n",
    "🔸 Exemple :  \n",
    "- Recommandation de films ou d’articles selon les sujets que vous lisez fréquemment.\n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣ Moteurs de recherche intelligents\n",
    "Les moteurs comme **Google** ou les fonctions de recherche sur des sites utilisent le NLP pour **comprendre l’intention** derrière une requête et proposer les résultats les plus pertinents.\n",
    "\n",
    "🔸 Exemple :  \n",
    "- Requête : *\"meilleurs restaurants végétariens à Lyon\"* → résultats localisés, classés, filtrés.\n",
    "\n",
    "---\n",
    "\n",
    "## 6️⃣ Détection de spam ou de contenu inapproprié\n",
    "Le NLP est utilisé pour analyser les messages ou contenus textuels afin de détecter les **spams, discours haineux, ou propos inappropriés**.\n",
    "\n",
    "🔸 Exemple :  \n",
    "- Blocage automatique d’un commentaire offensant sur un réseau social.\n",
    "\n",
    "---\n",
    "\n",
    "## 7️⃣ Résumé automatique de documents\n",
    "Certains outils peuvent générer un **résumé automatique** d’un article ou rapport à l’aide du NLP.\n",
    "\n",
    "🔸 Exemple :  \n",
    "- Un résumé de 3 lignes généré automatiquement à partir d’un article de 5 pages.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ En résumé\n",
    "\n",
    "| Application                | Utilisation principale                                 |\n",
    "|----------------------------|--------------------------------------------------------|\n",
    "| Assistants vocaux / Chatbots | Comprendre et répondre en langage naturel            |\n",
    "| Analyse d’avis clients      | Identifier les sentiments exprimés dans les textes    |\n",
    "| Traduction automatique      | Traduire des phrases entre différentes langues        |\n",
    "| Moteurs de recherche        | Comprendre les requêtes utilisateur                   |\n",
    "| Détection de spam           | Identifier les messages indésirables ou offensants    |\n",
    "| Résumé de documents         | Générer des résumés courts à partir de longs textes   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a8fef",
   "metadata": {},
   "source": [
    "# 🛑 Qu’est-ce qu’un Stop-Word en NLP ?\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Définition\n",
    "\n",
    "Un **stop-word** (ou mot vide) est un mot **très courant** dans une langue, qui n’apporte **pas ou peu d'information sémantique** à une phrase.  \n",
    "Ce sont généralement des mots comme :  \n",
    "➡️ *\"le\", \"la\", \"de\", \"et\", \"à\", \"un\", \"pour\", \"en\", \"est\", \"ce\", \"que\"*, etc.\n",
    "\n",
    "Ils sont souvent supprimés lors du prétraitement des textes, car ils **n’ont pas de valeur significative pour les tâches d’analyse** comme la classification, la recherche d’information ou l’extraction de mots-clés.\n",
    "\n",
    "---\n",
    "\n",
    "## ❓ Pourquoi supprimer les stop-words ?\n",
    "\n",
    "- ✅ **Réduction du bruit** : élimine les mots fréquents mais peu informatifs.\n",
    "- ✅ **Amélioration des performances** : réduction de la taille du vocabulaire, temps de calcul plus court.\n",
    "- ✅ **Accent mis sur les mots significatifs** : on se concentre sur les **substantifs, verbes, adjectifs** qui portent le sens.\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Exemple concret\n",
    "\n",
    "### 📝 Phrase brute :\n",
    "> *\"Le chat est sur le canapé et regarde la télévision.\"*\n",
    "\n",
    "### 🔍 Après suppression des stop-words :\n",
    "> *\"chat canapé regarde télévision\"*\n",
    "\n",
    "✅ On conserve uniquement les mots **porteurs de sens**.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Remarque\n",
    "\n",
    "La suppression de stop-words dépend du **contexte**.  \n",
    "Par exemple, dans une **analyse de style d’écriture** ou une **génération de texte**, ces mots peuvent être importants.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ En résumé\n",
    "\n",
    "| Élément             | Description                              |\n",
    "|---------------------|------------------------------------------|\n",
    "| Stop-word           | Mot fréquent sans valeur sémantique forte |\n",
    "| Objectif            | Réduire le bruit et simplifier l’analyse |\n",
    "| Exemples            | \"le\", \"et\", \"est\", \"ce\", \"de\", \"un\"       |\n",
    "| Résultat attendu    | Texte plus court et plus significatif     |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c6f62e",
   "metadata": {},
   "source": [
    "# ✂️ Traitement de la ponctuation et des caractères spéciaux en NLP\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 1. Pourquoi les traiter ?\n",
    "\n",
    "Lorsque l’on travaille sur des textes, il est fréquent de rencontrer :\n",
    "\n",
    "- des **signes de ponctuation** : `. , ! ? : ; \" ( )`\n",
    "- des **caractères spéciaux** : `@ # % $ & * + / = \\ | [ ] { } < > ~ ^`, etc.\n",
    "\n",
    "Ces éléments sont souvent **non pertinents** pour des tâches d’analyse automatique, et peuvent **perturber les algorithmes** s’ils ne sont pas correctement nettoyés.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔸 2. Traitement de la ponctuation\n",
    "\n",
    "### ✅ Que fait-on généralement ?\n",
    "- **Suppression** de la ponctuation lors du prétraitement.\n",
    "- **Conservation** possible dans certains cas (ex : analyse de sentiments ou d’émotions, où le point d’exclamation peut avoir un sens).\n",
    "\n",
    "### 📌 Exemple :\n",
    "> Phrase brute : *\"C'est incroyable ! Vraiment, tu crois ça ?\"*\n",
    "\n",
    "→ Après suppression de la ponctuation :  \n",
    "> `\"C est incroyable Vraiment tu crois ça\"`\n",
    "\n",
    "---\n",
    "\n",
    "## 🔸 3. Traitement des caractères spéciaux\n",
    "\n",
    "### ✅ Que fait-on généralement ?\n",
    "- **Suppression pure** : quand ils ne portent aucune information utile.\n",
    "- **Remplacement ou normalisation** : parfois on remplace des caractères spéciaux par leur équivalent textuel.\n",
    "\n",
    "### 📌 Exemple :\n",
    "> Texte brut : *\"Envoyez-moi un e-mail à : contact@exemple.com #urgent\"*  \n",
    "→ Après nettoyage :  \n",
    "> `\"Envoyez moi un e mail à contact exemple com urgent\"`\n",
    "\n",
    "---\n",
    "\n",
    "## 🔸 4. Outils de nettoyage automatique\n",
    "\n",
    "Des bibliothèques comme **NLTK**, **spaCy**, ou **re** (regex en Python) permettent de :\n",
    "- détecter et supprimer ponctuation et caractères spéciaux\n",
    "- normaliser les textes pour une meilleure analyse\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ En résumé\n",
    "\n",
    "| Élément à traiter     | Que fait-on ?                          | Pourquoi ?                                 |\n",
    "|-----------------------|----------------------------------------|--------------------------------------------|\n",
    "| Ponctuation           | Supprimée ou conservée selon le contexte | Réduit le bruit dans l’analyse             |\n",
    "| Caractères spéciaux   | Souvent supprimés ou remplacés         | Évite les erreurs d’analyse ou de tokenisation |\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Astuce\n",
    "\n",
    "Toujours adapter le **niveau de nettoyage** au **contexte de votre application** :  \n",
    "- En classification de texte : supprimez la ponctuation.  \n",
    "- En analyse émotionnelle : conservez `!`, `?`, `...` pour détecter l’intensité.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8e15d",
   "metadata": {},
   "source": [
    "# 🔠 Token et N-gram en NLP\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Qu’est-ce qu’un **token** ?\n",
    "\n",
    "Un **token** est une **unité de base** dans le traitement du langage naturel.  \n",
    "Il correspond généralement à un **mot**, mais cela peut aussi être un **symbole**, **un caractère**, ou même une **sous-partie de mot** selon la méthode utilisée.\n",
    "\n",
    "### 📌 Exemple :\n",
    "> Phrase : *\"Le chat dort.\"*\n",
    "\n",
    "→ Tokens : `[\"Le\", \"chat\", \"dort\", \".\"]`\n",
    "\n",
    "Ce processus s'appelle la **tokenisation**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔸 Pourquoi tokeniser un texte ?\n",
    "\n",
    "- Facilite l'analyse statistique du texte.\n",
    "- Permet de compter les mots, détecter les fréquences, etc.\n",
    "- Étape **indispensable** dans quasiment toutes les tâches de NLP.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Qu’est-ce qu’un **N-gram** ?\n",
    "\n",
    "Un **N-gram** est une **séquence de N tokens consécutifs** dans un texte.  \n",
    "Cela permet de capturer des **groupes de mots** au lieu d'analyser mot par mot.\n",
    "\n",
    "### 📌 Types de N-gram :\n",
    "- **Unigram** : séquences de 1 mot (tokens simples)\n",
    "- **Bigram** : séquences de 2 mots\n",
    "- **Trigram** : séquences de 3 mots\n",
    "- etc.\n",
    "\n",
    "### 🔍 Exemple (avec la phrase : *\"Le chat dort\"*) :\n",
    "\n",
    "| Type de N-gram | Résultat                                |\n",
    "|----------------|------------------------------------------|\n",
    "| Unigram        | `[\"Le\", \"chat\", \"dort\"]`                 |\n",
    "| Bigram         | `[(\"Le\", \"chat\"), (\"chat\", \"dort\")]`     |\n",
    "| Trigram        | `[(\"Le\", \"chat\", \"dort\")]`               |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔄 Quel processus permet de les obtenir ?\n",
    "\n",
    "### ✅ **La tokenisation**, suivie de la **génération de N-grams**.\n",
    "\n",
    "1. **Tokenisation** : découper le texte en mots (tokens).\n",
    "2. **Génération de N-grams** : former des groupes de N tokens consécutifs.\n",
    "\n",
    "### 🧰 Outils utilisés :\n",
    "- Bibliothèques Python : `nltk`, `spaCy`, `sklearn`, etc.\n",
    "- Méthodes : `nltk.ngrams()`, `CountVectorizer(ngram_range=(n, n))`\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ En résumé\n",
    "\n",
    "| Concept     | Définition                                     | Exemple                                      |\n",
    "|-------------|-------------------------------------------------|----------------------------------------------|\n",
    "| Token       | Unité élémentaire (mot, caractère, ...)         | `\"Le chat dort\"` → `[\"Le\", \"chat\", \"dort\"]`  |\n",
    "| N-gram      | Groupe de N tokens consécutifs                 | Bigram : `[(\"Le\", \"chat\"), (\"chat\", \"dort\")]`|\n",
    "| Processus   | Tokenisation puis combinaison                  | Utilisé pour analyse de structure, fréquence |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519977d0",
   "metadata": {},
   "source": [
    "# 🌱 Stemming vs Lemmatization en NLP\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Définition du **Stemming**\n",
    "\n",
    "Le **stemming** consiste à **réduire un mot à sa racine** (ou \"stem\"), sans nécessairement obtenir un mot réel.  \n",
    "C’est une méthode **rapide et heuristique**, souvent basée sur des règles simples de découpe de suffixes.\n",
    "\n",
    "### 📌 Exemple :\n",
    "- \"parler\", \"parlons\", \"parlait\", \"parlé\" → **\"parl\"**\n",
    "- \"chats\", \"chaton\" → **\"chat\"** (ou parfois \"cha\")\n",
    "\n",
    "👉 Le résultat peut être un **mot tronqué**, parfois incorrect ou inexistant.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Définition de la **Lemmatization**\n",
    "\n",
    "La **lemmatisation** consiste à ramener un mot à sa **forme canonique** (appelée *lemme*), tout en prenant en compte son **contexte grammatical** (temps, genre, nombre, etc.).\n",
    "\n",
    "### 📌 Exemple :\n",
    "- \"mangeons\", \"mangeais\", \"mangé\" → **\"manger\"**\n",
    "- \"meilleurs\", \"meilleure\" → **\"bon\"**\n",
    "\n",
    "👉 Le résultat est toujours un **mot du dictionnaire**, linguistiquement correct.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔸 Quelle est la différence ?\n",
    "\n",
    "| Critère                | Stemming                           | Lemmatization                          |\n",
    "|------------------------|------------------------------------|----------------------------------------|\n",
    "| 🔧 Approche            | Basée sur des règles simples       | Basée sur l’analyse linguistique       |\n",
    "| 🧠 Contexte grammatical | Ignoré                             | Pris en compte                         |\n",
    "| 📝 Résultat            | Parfois inexistant ou erroné       | Mot réel et correct                    |\n",
    "| ⚡ Vitesse              | Très rapide                        | Plus lent                              |\n",
    "| 🎯 Précision           | Moins précise                      | Plus précise                           |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Quand utiliser l’un ou l’autre ?\n",
    "\n",
    "| Situation / Besoin                         | Méthode conseillée   |\n",
    "|--------------------------------------------|-----------------------|\n",
    "| Analyse rapide, grande base de données     | ✅ **Stemming**        |\n",
    "| Qualité linguistique, traitement fin       | ✅ **Lemmatization**   |\n",
    "| Modèle sensible aux formes de mots         | ✅ **Lemmatization**   |\n",
    "| Cas multilingue simple, sans grammaire     | ✅ **Stemming**        |\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Exemple concret (en anglais) :\n",
    "\n",
    "> Phrase : *\"The children were playing outside.\"*\n",
    "\n",
    "- **Stemming** → `[\"the\", \"children\", \"were\", \"play\", \"outsid\"]`\n",
    "- **Lemmatization** → `[\"the\", \"child\", \"be\", \"play\", \"outside\"]`\n",
    "\n",
    "---\n",
    "\n",
    "## 🧰 Bibliothèques utiles en Python\n",
    "\n",
    "- **Stemming** : `nltk.stem.PorterStemmer`, `SnowballStemmer`\n",
    "- **Lemmatization** : `nltk.WordNetLemmatizer`, `spaCy`, `TextBlob`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cba580",
   "metadata": {},
   "source": [
    "# 🧠 Représentation vectorielle des textes : Bag of Words vs TF-IDF\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Pourquoi représenter les mots en vecteurs ?\n",
    "\n",
    "Les algorithmes de **Machine Learning** ne comprennent pas le langage humain.  \n",
    "Il faut donc **transformer les mots en valeurs numériques** pour les rendre exploitables.  \n",
    "Deux méthodes classiques pour cela sont :\n",
    "\n",
    "- **Bag of Words (BoW)**\n",
    "- **TF-IDF (Term Frequency - Inverse Document Frequency)**\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ Bag of Words (Sac de mots)\n",
    "\n",
    "### 🧠 Principe\n",
    "\n",
    "- Le texte est représenté par un **vecteur de fréquences** de mots.\n",
    "- Chaque mot du **vocabulaire total** est une dimension du vecteur.\n",
    "- On **compte simplement** combien de fois chaque mot apparaît.\n",
    "\n",
    "### 📌 Exemple :\n",
    "\n",
    "Corpus de deux phrases :\n",
    "1. *\"Le chat dort.\"*\n",
    "2. *\"Le chien aboie.\"*\n",
    "\n",
    "Vocabulaire : `[\"Le\", \"chat\", \"dort\", \"chien\", \"aboie\"]`\n",
    "\n",
    "| Texte                 | Vecteur BoW                 |\n",
    "|-----------------------|-----------------------------|\n",
    "| \"Le chat dort\"        | [1, 1, 1, 0, 0]              |\n",
    "| \"Le chien aboie\"      | [1, 0, 0, 1, 1]              |\n",
    "\n",
    "### ✅ Avantages :\n",
    "- Simple à implémenter\n",
    "- Fonctionne bien avec des modèles de base (Naive Bayes, SVM)\n",
    "\n",
    "### ❌ Inconvénients :\n",
    "- Ne prend pas en compte le **sens** des mots\n",
    "- Les mots fréquents mais peu informatifs (ex. \"le\", \"et\") peuvent **dominer**\n",
    "- Pas d'information sur l'**importance relative d’un mot** dans le corpus\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "### 🧠 Principe\n",
    "\n",
    "TF-IDF vise à pondérer les mots en fonction de :\n",
    "- **TF (Term Frequency)** : fréquence du mot dans un document.\n",
    "- **IDF (Inverse Document Frequency)** : importance du mot dans **l’ensemble du corpus**.\n",
    "\n",
    "👉 Un mot fréquent **dans un document** mais **rare dans le corpus** aura un **poids élevé**.  \n",
    "Les mots trop courants (ex. \"le\", \"est\") ont un poids faible.\n",
    "\n",
    "### 🔢 Formule :\n",
    "\n",
    "TF-IDF(w, d, D) = TF(w, d) × log(N / DF(w))  \n",
    "\n",
    "\n",
    "- `w` : mot\n",
    "- `d` : document\n",
    "- `D` : ensemble des documents\n",
    "- `N` : nombre total de documents\n",
    "- `DF(w)` : nombre de documents contenant `w`\n",
    "\n",
    "### 📌 Exemple :\n",
    "\n",
    "Même corpus :  \n",
    "1. *\"Le chat dort.\"*  \n",
    "2. *\"Le chien aboie.\"*\n",
    "\n",
    "Le mot \"Le\" apparaît dans **tous les documents** ⇒ **IDF faible**  \n",
    "Le mot \"chat\" n’apparaît que dans 1 doc ⇒ **IDF élevé**\n",
    "\n",
    "| Mot     | TF dans doc1 | IDF approx. | TF-IDF doc1 |\n",
    "|----------|--------------|--------------|--------------|\n",
    "| le       | 1            | log(2/2) = 0 | 0            |\n",
    "| chat     | 1            | log(2/1)     | élevé        |\n",
    "| dort     | 1            | log(2/1)     | élevé        |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔄 Différences principales\n",
    "\n",
    "| Critère                     | Bag of Words                          | TF-IDF                                 |\n",
    "|-----------------------------|----------------------------------------|----------------------------------------|\n",
    "| Pondération des mots        | Basée uniquement sur la fréquence      | Tient compte de la rareté du mot       |\n",
    "| Mots fréquents              | Peuvent dominer l’analyse              | Pénalisés s’ils sont trop fréquents    |\n",
    "| Pertinence sémantique       | Faible                                 | Meilleure que BoW                      |\n",
    "| Complexité                  | Simple                                 | Un peu plus complexe                   |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ En résumé\n",
    "\n",
    "| Méthode   | Avantages                           | Inconvénients                        | Utilisation typique                   |\n",
    "|-----------|--------------------------------------|--------------------------------------|----------------------------------------|\n",
    "| BoW       | Simple, rapide, facile à comprendre  | Ne tient pas compte du contexte      | Modèles de base, classification rapide |\n",
    "| TF-IDF    | Pondère selon l’importance du mot    | Ne capture pas l’ordre des mots      | Recherche, analyse fine, clustering    |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
