{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e457f91f",
   "metadata": {},
   "source": [
    "# üìò Exploration de Texte (Text Mining) vs Traitement du Langage Naturel (NLP)\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ D√©finition du Text Mining (Exploration de texte)\n",
    "\n",
    "Le **Text Mining** d√©signe l'ensemble des techniques permettant d'extraire des informations utiles ou cach√©es √† partir de grands volumes de **textes non structur√©s**. Il s'agit d'une forme sp√©cifique de fouille de donn√©es (data mining) appliqu√©e aux donn√©es textuelles.\n",
    "\n",
    "**Objectifs principaux :**\n",
    "- Identifier des tendances, th√®mes ou opinions (ex. : analyse de sentiments).\n",
    "- Extraire des entit√©s nomm√©es (personnes, lieux, dates).\n",
    "- R√©sumer automatiquement des documents.\n",
    "- Classifier ou regrouper des textes.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ D√©finition du Natural Language Processing (NLP)\n",
    "\n",
    "Le **Traitement Automatique du Langage Naturel (TAL ou NLP)** est une branche de l‚Äôintelligence artificielle visant √† permettre aux machines de **comprendre, interpr√©ter, manipuler et g√©n√©rer** du langage humain.\n",
    "\n",
    "**Applications typiques :**\n",
    "- Traduction automatique (ex. : Google Translate).\n",
    "- G√©n√©ration de texte (ex. : chatbots).\n",
    "- Analyse syntaxique et grammaticale.\n",
    "- Reconnaissance d'entit√©s nomm√©es.\n",
    "- Synth√®se et reconnaissance vocale.\n",
    "\n",
    "---\n",
    "\n",
    "## üî∏ Points communs entre Text Mining et NLP\n",
    "\n",
    "- üåê **Travail sur le langage naturel** (texte non structur√©).\n",
    "- üß† **Utilisation de techniques similaires** : tokenisation, lemmatisation, analyse syntaxique, etc.\n",
    "- ü§ñ **Domaines de l‚Äôintelligence artificielle**, souvent appuy√©s par le Machine Learning.\n",
    "- üì¶ **But commun d‚Äôextraction d‚Äôinformation** et d‚Äôanalyse de texte.\n",
    "\n",
    "---\n",
    "\n",
    "## üî∏ Diff√©rences entre Text Mining et NLP\n",
    "\n",
    "| Crit√®re                        | Text Mining                                     | Natural Language Processing (NLP)               |\n",
    "|-------------------------------|--------------------------------------------------|-------------------------------------------------|\n",
    "| üéØ Objectif principal         | Extraire de l'information √† partir de textes     | Comprendre et manipuler le langage naturel      |\n",
    "| üß∞ Outils utilis√©s             | Statistiques, classification, clustering         | Grammaires, mod√®les linguistiques, IA           |\n",
    "| üß© Approche                   | Analyse orient√©e donn√©es                         | Analyse orient√©e langage                        |\n",
    "| üìù Type de sortie             | R√©sum√©s, clusters, visualisations                | Traductions, textes g√©n√©r√©s, r√©ponses automatiques |\n",
    "| üîÑ Relation                   | Utilise des techniques NLP                      | Domaine plus large incluant le Text Mining      |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ R√©sum√©\n",
    "\n",
    "- Le **Text Mining** est une **application sp√©cifique** utilisant des techniques de **NLP** pour extraire de l'information utile de textes.\n",
    "- Le **NLP** est un **domaine plus g√©n√©ral** d√©di√© √† la compr√©hension et au traitement du langage humain.\n",
    "- Les deux sont **compl√©mentaires** et souvent utilis√©s ensemble dans les syst√®mes d‚Äôanalyse textuelle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679aaf1",
   "metadata": {},
   "source": [
    "# üîç Sous-domaines du NLP (Traitement du Langage Naturel)\n",
    "\n",
    "Le NLP regroupe plusieurs techniques et sous-domaines permettant aux machines de comprendre et manipuler le langage humain. Voici trois sous-domaines essentiels :\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Analyse de sentiments (Sentiment Analysis)\n",
    "\n",
    "### üß† D√©finition\n",
    "L‚Äôanalyse de sentiments vise √† **d√©terminer l‚Äô√©motion ou l‚Äôopinion** exprim√©e dans un texte. Elle est souvent utilis√©e pour analyser les avis clients, les tweets, ou les commentaires.\n",
    "\n",
    "### üìå Exemples :\n",
    "- Texte : *\"J'adore ce produit, il est vraiment efficace !\"*  \n",
    "  ‚Üí Sentiment : **positif**\n",
    "\n",
    "- Texte : *\"Ce service est horrible, je ne le recommande √† personne.\"*  \n",
    "  ‚Üí Sentiment : **n√©gatif**\n",
    "\n",
    "### üì¶ Applications :\n",
    "- E-r√©putation\n",
    "- Marketing digital\n",
    "- Veille concurrentielle\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Reconnaissance d'entit√©s nomm√©es (Named Entity Recognition - NER)\n",
    "\n",
    "### üß† D√©finition\n",
    "La **NER** permet d‚Äôidentifier et de classer automatiquement des **entit√©s** dans un texte (comme les **noms de personnes**, **lieux**, **dates**, **organisations**, etc.).\n",
    "\n",
    "### üìå Exemples :\n",
    "- Texte : *\"Emmanuel Macron a visit√© Berlin le 12 mars 2023.\"*  \n",
    "  ‚Üí Entit√©s extraites :\n",
    "  - **Personne** : Emmanuel Macron  \n",
    "  - **Lieu** : Berlin  \n",
    "  - **Date** : 12 mars 2023\n",
    "\n",
    "### üì¶ Applications :\n",
    "- Extraction d‚Äôinformation\n",
    "- Moteurs de recherche intelligents\n",
    "- Syst√®mes de question-r√©ponse\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ √âtiquetage morpho-syntaxique (Part-of-Speech Tagging - POS Tagging)\n",
    "\n",
    "### üß† D√©finition\n",
    "Le POS tagging consiste √† attribuer √† chaque mot d'une phrase sa **cat√©gorie grammaticale** (nom, verbe, adjectif, etc.).\n",
    "\n",
    "### üìå Exemple :\n",
    "- Phrase : *\"Le chat dort sur le canap√©.\"*  \n",
    "  ‚Üí R√©sultat :\n",
    "  - Le ‚Üí D√©terminant (DET)\n",
    "  - chat ‚Üí Nom (NOUN)\n",
    "  - dort ‚Üí Verbe (VERB)\n",
    "  - sur ‚Üí Pr√©position (PREP)\n",
    "  - le ‚Üí D√©terminant (DET)\n",
    "  - canap√© ‚Üí Nom (NOUN)\n",
    "\n",
    "### üì¶ Applications :\n",
    "- Analyse grammaticale\n",
    "- Traduction automatique\n",
    "- R√©solution d‚Äôambigu√Øt√©s linguistiques\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ En r√©sum√©\n",
    "\n",
    "| Sous-domaine        | Objectif principal                                 | Exemple d‚Äôapplication                  |\n",
    "|---------------------|----------------------------------------------------|----------------------------------------|\n",
    "| Analyse de sentiments | D√©terminer l‚Äô√©motion dans un texte                | √âtude d‚Äôavis clients                   |\n",
    "| NER                  | Identifier des entit√©s nomm√©es                     | Extraction d‚Äôinformations biographiques |\n",
    "| POS Tagging          | Identifier les cat√©gories grammaticales des mots  | Analyse syntaxique                     |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec0779",
   "metadata": {},
   "source": [
    "# üí° Applications concr√®tes du NLP\n",
    "\n",
    "Le NLP est largement utilis√© dans de nombreux domaines du quotidien et de l'industrie. Voici quelques exemples d'applications concr√®tes :\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Assistants vocaux et chatbots\n",
    "Les assistants comme **Siri, Alexa, Google Assistant** ou les **chatbots** utilisent le NLP pour comprendre les commandes vocales ou √©crites, et y r√©pondre de mani√®re naturelle.\n",
    "\n",
    "üî∏ Exemple :  \n",
    "- *\"Quel temps fait-il aujourd‚Äôhui ?\"* ‚Üí r√©ponse vocale ou textuelle fournie par l‚Äôassistant.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Analyse d‚Äôavis clients (Sentiment Analysis)\n",
    "Les entreprises utilisent le NLP pour analyser automatiquement les **avis en ligne** afin de comprendre l‚Äôopinion des clients sur leurs produits ou services.\n",
    "\n",
    "üî∏ Exemple :  \n",
    "- *\"Le service est trop lent et le personnel d√©sagr√©able.\"* ‚Üí sentiment n√©gatif.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Traduction automatique\n",
    "Les outils comme **Google Translate** utilisent le NLP pour traduire un texte d‚Äôune langue √† une autre en conservant le sens.\n",
    "\n",
    "üî∏ Exemple :  \n",
    "- Traduction de *\"Bonjour, comment allez-vous ?\"* en *\"Hello, how are you?\"*\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Syst√®mes de recommandation\n",
    "Le NLP peut analyser les contenus consult√©s (articles, livres, vid√©os) pour proposer des **recommandations personnalis√©es** bas√©es sur les pr√©f√©rences linguistiques de l‚Äôutilisateur.\n",
    "\n",
    "üî∏ Exemple :  \n",
    "- Recommandation de films ou d‚Äôarticles selon les sujets que vous lisez fr√©quemment.\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Moteurs de recherche intelligents\n",
    "Les moteurs comme **Google** ou les fonctions de recherche sur des sites utilisent le NLP pour **comprendre l‚Äôintention** derri√®re une requ√™te et proposer les r√©sultats les plus pertinents.\n",
    "\n",
    "üî∏ Exemple :  \n",
    "- Requ√™te : *\"meilleurs restaurants v√©g√©tariens √† Lyon\"* ‚Üí r√©sultats localis√©s, class√©s, filtr√©s.\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ D√©tection de spam ou de contenu inappropri√©\n",
    "Le NLP est utilis√© pour analyser les messages ou contenus textuels afin de d√©tecter les **spams, discours haineux, ou propos inappropri√©s**.\n",
    "\n",
    "üî∏ Exemple :  \n",
    "- Blocage automatique d‚Äôun commentaire offensant sur un r√©seau social.\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ R√©sum√© automatique de documents\n",
    "Certains outils peuvent g√©n√©rer un **r√©sum√© automatique** d‚Äôun article ou rapport √† l‚Äôaide du NLP.\n",
    "\n",
    "üî∏ Exemple :  \n",
    "- Un r√©sum√© de 3 lignes g√©n√©r√© automatiquement √† partir d‚Äôun article de 5 pages.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ En r√©sum√©\n",
    "\n",
    "| Application                | Utilisation principale                                 |\n",
    "|----------------------------|--------------------------------------------------------|\n",
    "| Assistants vocaux / Chatbots | Comprendre et r√©pondre en langage naturel            |\n",
    "| Analyse d‚Äôavis clients      | Identifier les sentiments exprim√©s dans les textes    |\n",
    "| Traduction automatique      | Traduire des phrases entre diff√©rentes langues        |\n",
    "| Moteurs de recherche        | Comprendre les requ√™tes utilisateur                   |\n",
    "| D√©tection de spam           | Identifier les messages ind√©sirables ou offensants    |\n",
    "| R√©sum√© de documents         | G√©n√©rer des r√©sum√©s courts √† partir de longs textes   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a8fef",
   "metadata": {},
   "source": [
    "# üõë Qu‚Äôest-ce qu‚Äôun Stop-Word en NLP ?\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ D√©finition\n",
    "\n",
    "Un **stop-word** (ou mot vide) est un mot **tr√®s courant** dans une langue, qui n‚Äôapporte **pas ou peu d'information s√©mantique** √† une phrase.  \n",
    "Ce sont g√©n√©ralement des mots comme :  \n",
    "‚û°Ô∏è *\"le\", \"la\", \"de\", \"et\", \"√†\", \"un\", \"pour\", \"en\", \"est\", \"ce\", \"que\"*, etc.\n",
    "\n",
    "Ils sont souvent supprim√©s lors du pr√©traitement des textes, car ils **n‚Äôont pas de valeur significative pour les t√¢ches d‚Äôanalyse** comme la classification, la recherche d‚Äôinformation ou l‚Äôextraction de mots-cl√©s.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùì Pourquoi supprimer les stop-words ?\n",
    "\n",
    "- ‚úÖ **R√©duction du bruit** : √©limine les mots fr√©quents mais peu informatifs.\n",
    "- ‚úÖ **Am√©lioration des performances** : r√©duction de la taille du vocabulaire, temps de calcul plus court.\n",
    "- ‚úÖ **Accent mis sur les mots significatifs** : on se concentre sur les **substantifs, verbes, adjectifs** qui portent le sens.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Exemple concret\n",
    "\n",
    "### üìù Phrase brute :\n",
    "> *\"Le chat est sur le canap√© et regarde la t√©l√©vision.\"*\n",
    "\n",
    "### üîç Apr√®s suppression des stop-words :\n",
    "> *\"chat canap√© regarde t√©l√©vision\"*\n",
    "\n",
    "‚úÖ On conserve uniquement les mots **porteurs de sens**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Remarque\n",
    "\n",
    "La suppression de stop-words d√©pend du **contexte**.  \n",
    "Par exemple, dans une **analyse de style d‚Äô√©criture** ou une **g√©n√©ration de texte**, ces mots peuvent √™tre importants.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ En r√©sum√©\n",
    "\n",
    "| √âl√©ment             | Description                              |\n",
    "|---------------------|------------------------------------------|\n",
    "| Stop-word           | Mot fr√©quent sans valeur s√©mantique forte |\n",
    "| Objectif            | R√©duire le bruit et simplifier l‚Äôanalyse |\n",
    "| Exemples            | \"le\", \"et\", \"est\", \"ce\", \"de\", \"un\"       |\n",
    "| R√©sultat attendu    | Texte plus court et plus significatif     |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c6f62e",
   "metadata": {},
   "source": [
    "# ‚úÇÔ∏è Traitement de la ponctuation et des caract√®res sp√©ciaux en NLP\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 1. Pourquoi les traiter ?\n",
    "\n",
    "Lorsque l‚Äôon travaille sur des textes, il est fr√©quent de rencontrer :\n",
    "\n",
    "- des **signes de ponctuation** : `. , ! ? : ; \" ( )`\n",
    "- des **caract√®res sp√©ciaux** : `@ # % $ & * + / = \\ | [ ] { } < > ~ ^`, etc.\n",
    "\n",
    "Ces √©l√©ments sont souvent **non pertinents** pour des t√¢ches d‚Äôanalyse automatique, et peuvent **perturber les algorithmes** s‚Äôils ne sont pas correctement nettoy√©s.\n",
    "\n",
    "---\n",
    "\n",
    "## üî∏ 2. Traitement de la ponctuation\n",
    "\n",
    "### ‚úÖ Que fait-on g√©n√©ralement ?\n",
    "- **Suppression** de la ponctuation lors du pr√©traitement.\n",
    "- **Conservation** possible dans certains cas (ex : analyse de sentiments ou d‚Äô√©motions, o√π le point d‚Äôexclamation peut avoir un sens).\n",
    "\n",
    "### üìå Exemple :\n",
    "> Phrase brute : *\"C'est incroyable ! Vraiment, tu crois √ßa ?\"*\n",
    "\n",
    "‚Üí Apr√®s suppression de la ponctuation :  \n",
    "> `\"C est incroyable Vraiment tu crois √ßa\"`\n",
    "\n",
    "---\n",
    "\n",
    "## üî∏ 3. Traitement des caract√®res sp√©ciaux\n",
    "\n",
    "### ‚úÖ Que fait-on g√©n√©ralement ?\n",
    "- **Suppression pure** : quand ils ne portent aucune information utile.\n",
    "- **Remplacement ou normalisation** : parfois on remplace des caract√®res sp√©ciaux par leur √©quivalent textuel.\n",
    "\n",
    "### üìå Exemple :\n",
    "> Texte brut : *\"Envoyez-moi un e-mail √† : contact@exemple.com #urgent\"*  \n",
    "‚Üí Apr√®s nettoyage :  \n",
    "> `\"Envoyez moi un e mail √† contact exemple com urgent\"`\n",
    "\n",
    "---\n",
    "\n",
    "## üî∏ 4. Outils de nettoyage automatique\n",
    "\n",
    "Des biblioth√®ques comme **NLTK**, **spaCy**, ou **re** (regex en Python) permettent de :\n",
    "- d√©tecter et supprimer ponctuation et caract√®res sp√©ciaux\n",
    "- normaliser les textes pour une meilleure analyse\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ En r√©sum√©\n",
    "\n",
    "| √âl√©ment √† traiter     | Que fait-on ?                          | Pourquoi ?                                 |\n",
    "|-----------------------|----------------------------------------|--------------------------------------------|\n",
    "| Ponctuation           | Supprim√©e ou conserv√©e selon le contexte | R√©duit le bruit dans l‚Äôanalyse             |\n",
    "| Caract√®res sp√©ciaux   | Souvent supprim√©s ou remplac√©s         | √âvite les erreurs d‚Äôanalyse ou de tokenisation |\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Astuce\n",
    "\n",
    "Toujours adapter le **niveau de nettoyage** au **contexte de votre application** :  \n",
    "- En classification de texte : supprimez la ponctuation.  \n",
    "- En analyse √©motionnelle : conservez `!`, `?`, `...` pour d√©tecter l‚Äôintensit√©.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8e15d",
   "metadata": {},
   "source": [
    "# üî† Token et N-gram en NLP\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Qu‚Äôest-ce qu‚Äôun **token** ?\n",
    "\n",
    "Un **token** est une **unit√© de base** dans le traitement du langage naturel.  \n",
    "Il correspond g√©n√©ralement √† un **mot**, mais cela peut aussi √™tre un **symbole**, **un caract√®re**, ou m√™me une **sous-partie de mot** selon la m√©thode utilis√©e.\n",
    "\n",
    "### üìå Exemple :\n",
    "> Phrase : *\"Le chat dort.\"*\n",
    "\n",
    "‚Üí Tokens : `[\"Le\", \"chat\", \"dort\", \".\"]`\n",
    "\n",
    "Ce processus s'appelle la **tokenisation**.\n",
    "\n",
    "---\n",
    "\n",
    "## üî∏ Pourquoi tokeniser un texte ?\n",
    "\n",
    "- Facilite l'analyse statistique du texte.\n",
    "- Permet de compter les mots, d√©tecter les fr√©quences, etc.\n",
    "- √âtape **indispensable** dans quasiment toutes les t√¢ches de NLP.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Qu‚Äôest-ce qu‚Äôun **N-gram** ?\n",
    "\n",
    "Un **N-gram** est une **s√©quence de N tokens cons√©cutifs** dans un texte.  \n",
    "Cela permet de capturer des **groupes de mots** au lieu d'analyser mot par mot.\n",
    "\n",
    "### üìå Types de N-gram :\n",
    "- **Unigram** : s√©quences de 1 mot (tokens simples)\n",
    "- **Bigram** : s√©quences de 2 mots\n",
    "- **Trigram** : s√©quences de 3 mots\n",
    "- etc.\n",
    "\n",
    "### üîç Exemple (avec la phrase : *\"Le chat dort\"*) :\n",
    "\n",
    "| Type de N-gram | R√©sultat                                |\n",
    "|----------------|------------------------------------------|\n",
    "| Unigram        | `[\"Le\", \"chat\", \"dort\"]`                 |\n",
    "| Bigram         | `[(\"Le\", \"chat\"), (\"chat\", \"dort\")]`     |\n",
    "| Trigram        | `[(\"Le\", \"chat\", \"dort\")]`               |\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Quel processus permet de les obtenir ?\n",
    "\n",
    "### ‚úÖ **La tokenisation**, suivie de la **g√©n√©ration de N-grams**.\n",
    "\n",
    "1. **Tokenisation** : d√©couper le texte en mots (tokens).\n",
    "2. **G√©n√©ration de N-grams** : former des groupes de N tokens cons√©cutifs.\n",
    "\n",
    "### üß∞ Outils utilis√©s :\n",
    "- Biblioth√®ques Python : `nltk`, `spaCy`, `sklearn`, etc.\n",
    "- M√©thodes : `nltk.ngrams()`, `CountVectorizer(ngram_range=(n, n))`\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ En r√©sum√©\n",
    "\n",
    "| Concept     | D√©finition                                     | Exemple                                      |\n",
    "|-------------|-------------------------------------------------|----------------------------------------------|\n",
    "| Token       | Unit√© √©l√©mentaire (mot, caract√®re, ...)         | `\"Le chat dort\"` ‚Üí `[\"Le\", \"chat\", \"dort\"]`  |\n",
    "| N-gram      | Groupe de N tokens cons√©cutifs                 | Bigram : `[(\"Le\", \"chat\"), (\"chat\", \"dort\")]`|\n",
    "| Processus   | Tokenisation puis combinaison                  | Utilis√© pour analyse de structure, fr√©quence |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519977d0",
   "metadata": {},
   "source": [
    "# üå± Stemming vs Lemmatization en NLP\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ D√©finition du **Stemming**\n",
    "\n",
    "Le **stemming** consiste √† **r√©duire un mot √† sa racine** (ou \"stem\"), sans n√©cessairement obtenir un mot r√©el.  \n",
    "C‚Äôest une m√©thode **rapide et heuristique**, souvent bas√©e sur des r√®gles simples de d√©coupe de suffixes.\n",
    "\n",
    "### üìå Exemple :\n",
    "- \"parler\", \"parlons\", \"parlait\", \"parl√©\" ‚Üí **\"parl\"**\n",
    "- \"chats\", \"chaton\" ‚Üí **\"chat\"** (ou parfois \"cha\")\n",
    "\n",
    "üëâ Le r√©sultat peut √™tre un **mot tronqu√©**, parfois incorrect ou inexistant.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ D√©finition de la **Lemmatization**\n",
    "\n",
    "La **lemmatisation** consiste √† ramener un mot √† sa **forme canonique** (appel√©e *lemme*), tout en prenant en compte son **contexte grammatical** (temps, genre, nombre, etc.).\n",
    "\n",
    "### üìå Exemple :\n",
    "- \"mangeons\", \"mangeais\", \"mang√©\" ‚Üí **\"manger\"**\n",
    "- \"meilleurs\", \"meilleure\" ‚Üí **\"bon\"**\n",
    "\n",
    "üëâ Le r√©sultat est toujours un **mot du dictionnaire**, linguistiquement correct.\n",
    "\n",
    "---\n",
    "\n",
    "## üî∏ Quelle est la diff√©rence ?\n",
    "\n",
    "| Crit√®re                | Stemming                           | Lemmatization                          |\n",
    "|------------------------|------------------------------------|----------------------------------------|\n",
    "| üîß Approche            | Bas√©e sur des r√®gles simples       | Bas√©e sur l‚Äôanalyse linguistique       |\n",
    "| üß† Contexte grammatical | Ignor√©                             | Pris en compte                         |\n",
    "| üìù R√©sultat            | Parfois inexistant ou erron√©       | Mot r√©el et correct                    |\n",
    "| ‚ö° Vitesse              | Tr√®s rapide                        | Plus lent                              |\n",
    "| üéØ Pr√©cision           | Moins pr√©cise                      | Plus pr√©cise                           |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Quand utiliser l‚Äôun ou l‚Äôautre ?\n",
    "\n",
    "| Situation / Besoin                         | M√©thode conseill√©e   |\n",
    "|--------------------------------------------|-----------------------|\n",
    "| Analyse rapide, grande base de donn√©es     | ‚úÖ **Stemming**        |\n",
    "| Qualit√© linguistique, traitement fin       | ‚úÖ **Lemmatization**   |\n",
    "| Mod√®le sensible aux formes de mots         | ‚úÖ **Lemmatization**   |\n",
    "| Cas multilingue simple, sans grammaire     | ‚úÖ **Stemming**        |\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Exemple concret (en anglais) :\n",
    "\n",
    "> Phrase : *\"The children were playing outside.\"*\n",
    "\n",
    "- **Stemming** ‚Üí `[\"the\", \"children\", \"were\", \"play\", \"outsid\"]`\n",
    "- **Lemmatization** ‚Üí `[\"the\", \"child\", \"be\", \"play\", \"outside\"]`\n",
    "\n",
    "---\n",
    "\n",
    "## üß∞ Biblioth√®ques utiles en Python\n",
    "\n",
    "- **Stemming** : `nltk.stem.PorterStemmer`, `SnowballStemmer`\n",
    "- **Lemmatization** : `nltk.WordNetLemmatizer`, `spaCy`, `TextBlob`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cba580",
   "metadata": {},
   "source": [
    "# üß† Repr√©sentation vectorielle des textes : Bag of Words vs TF-IDF\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Pourquoi repr√©senter les mots en vecteurs ?\n",
    "\n",
    "Les algorithmes de **Machine Learning** ne comprennent pas le langage humain.  \n",
    "Il faut donc **transformer les mots en valeurs num√©riques** pour les rendre exploitables.  \n",
    "Deux m√©thodes classiques pour cela sont :\n",
    "\n",
    "- **Bag of Words (BoW)**\n",
    "- **TF-IDF (Term Frequency - Inverse Document Frequency)**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Bag of Words (Sac de mots)\n",
    "\n",
    "### üß† Principe\n",
    "\n",
    "- Le texte est repr√©sent√© par un **vecteur de fr√©quences** de mots.\n",
    "- Chaque mot du **vocabulaire total** est une dimension du vecteur.\n",
    "- On **compte simplement** combien de fois chaque mot appara√Æt.\n",
    "\n",
    "### üìå Exemple :\n",
    "\n",
    "Corpus de deux phrases :\n",
    "1. *\"Le chat dort.\"*\n",
    "2. *\"Le chien aboie.\"*\n",
    "\n",
    "Vocabulaire : `[\"Le\", \"chat\", \"dort\", \"chien\", \"aboie\"]`\n",
    "\n",
    "| Texte                 | Vecteur BoW                 |\n",
    "|-----------------------|-----------------------------|\n",
    "| \"Le chat dort\"        | [1, 1, 1, 0, 0]              |\n",
    "| \"Le chien aboie\"      | [1, 0, 0, 1, 1]              |\n",
    "\n",
    "### ‚úÖ Avantages :\n",
    "- Simple √† impl√©menter\n",
    "- Fonctionne bien avec des mod√®les de base (Naive Bayes, SVM)\n",
    "\n",
    "### ‚ùå Inconv√©nients :\n",
    "- Ne prend pas en compte le **sens** des mots\n",
    "- Les mots fr√©quents mais peu informatifs (ex. \"le\", \"et\") peuvent **dominer**\n",
    "- Pas d'information sur l'**importance relative d‚Äôun mot** dans le corpus\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "### üß† Principe\n",
    "\n",
    "TF-IDF vise √† pond√©rer les mots en fonction de :\n",
    "- **TF (Term Frequency)** : fr√©quence du mot dans un document.\n",
    "- **IDF (Inverse Document Frequency)** : importance du mot dans **l‚Äôensemble du corpus**.\n",
    "\n",
    "üëâ Un mot fr√©quent **dans un document** mais **rare dans le corpus** aura un **poids √©lev√©**.  \n",
    "Les mots trop courants (ex. \"le\", \"est\") ont un poids faible.\n",
    "\n",
    "### üî¢ Formule :\n",
    "\n",
    "TF-IDF(w, d, D) = TF(w, d) √ó log(N / DF(w))  \n",
    "\n",
    "\n",
    "- `w` : mot\n",
    "- `d` : document\n",
    "- `D` : ensemble des documents\n",
    "- `N` : nombre total de documents\n",
    "- `DF(w)` : nombre de documents contenant `w`\n",
    "\n",
    "### üìå Exemple :\n",
    "\n",
    "M√™me corpus :  \n",
    "1. *\"Le chat dort.\"*  \n",
    "2. *\"Le chien aboie.\"*\n",
    "\n",
    "Le mot \"Le\" appara√Æt dans **tous les documents** ‚áí **IDF faible**  \n",
    "Le mot \"chat\" n‚Äôappara√Æt que dans 1 doc ‚áí **IDF √©lev√©**\n",
    "\n",
    "| Mot     | TF dans doc1 | IDF approx. | TF-IDF doc1 |\n",
    "|----------|--------------|--------------|--------------|\n",
    "| le       | 1            | log(2/2) = 0 | 0            |\n",
    "| chat     | 1            | log(2/1)     | √©lev√©        |\n",
    "| dort     | 1            | log(2/1)     | √©lev√©        |\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Diff√©rences principales\n",
    "\n",
    "| Crit√®re                     | Bag of Words                          | TF-IDF                                 |\n",
    "|-----------------------------|----------------------------------------|----------------------------------------|\n",
    "| Pond√©ration des mots        | Bas√©e uniquement sur la fr√©quence      | Tient compte de la raret√© du mot       |\n",
    "| Mots fr√©quents              | Peuvent dominer l‚Äôanalyse              | P√©nalis√©s s‚Äôils sont trop fr√©quents    |\n",
    "| Pertinence s√©mantique       | Faible                                 | Meilleure que BoW                      |\n",
    "| Complexit√©                  | Simple                                 | Un peu plus complexe                   |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ En r√©sum√©\n",
    "\n",
    "| M√©thode   | Avantages                           | Inconv√©nients                        | Utilisation typique                   |\n",
    "|-----------|--------------------------------------|--------------------------------------|----------------------------------------|\n",
    "| BoW       | Simple, rapide, facile √† comprendre  | Ne tient pas compte du contexte      | Mod√®les de base, classification rapide |\n",
    "| TF-IDF    | Pond√®re selon l‚Äôimportance du mot    | Ne capture pas l‚Äôordre des mots      | Recherche, analyse fine, clustering    |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
